{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in desired EV interval model numbers first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 20\n",
    "data_dir = os.path.join(os.getcwd(), \"dataGeneration\")\n",
    "\n",
    "EV_model_files = np.load(os.path.join(data_dir, f\"Interval_{interval}_model.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in model file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total feature_target number:  1755\n",
      "Total model number:  1755\n"
     ]
    }
   ],
   "source": [
    "read_path = \"dataGeneration/feature_target\"\n",
    "model_path = \"dataGeneration/model\"\n",
    "\n",
    "feature_target_dir = os.path.join(os.getcwd(), read_path)\n",
    "feature_target_files = os.listdir(feature_target_dir)\n",
    "print(\"Total feature_target number: \", len(feature_target_files))\n",
    "\n",
    "model_dir = os.path.join(os.getcwd(), model_path)\n",
    "model_files = os.listdir(model_dir)\n",
    "print(\"Total model number: \", len(model_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "\n",
    "for file in EV_model_files:\n",
    "# for file in range(len(feature_target_files)):\n",
    "    with open(os.path.join(feature_target_dir, f\"dataPoint_{file}.pkl\"), 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "        sample.append(loaded_dict)\n",
    "        f.close()\n",
    "\n",
    "# for reading all samples\n",
    "# for file in feature_target_files:\n",
    "#     with open(os.path.join(feature_target_dir, file), 'rb') as f:\n",
    "#         loaded_dict = pickle.load(f)\n",
    "#         sample.append(loaded_dict)\n",
    "#         f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out EV numbers to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample number:  800\n",
      "48000\n"
     ]
    }
   ],
   "source": [
    "nbEVMatrix = np.array([x[\"nbEV\"] for x in sample])\n",
    "\n",
    "# print(nbEVMatrix)\n",
    "print(\"Sample number: \", len(nbEVMatrix))\n",
    "print(np.sum(nbEVMatrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 66, 48) (800, 3, 48)\n",
      "66 3 48 800\n"
     ]
    }
   ],
   "source": [
    "loadMatrix = np.array([x[\"Load\"] for x in sample])\n",
    "solarMatrix = np.array([x[\"Solar\"] for x in sample])\n",
    "\n",
    "nbBus = loadMatrix.shape[1]\n",
    "nbSolar = solarMatrix.shape[1]\n",
    "nbTime = loadMatrix.shape[2]\n",
    "nbSample = loadMatrix.shape[0]\n",
    "\n",
    "nbSample = loadMatrix.shape[0]\n",
    "\n",
    "print(loadMatrix.shape, solarMatrix.shape)\n",
    "print(nbBus, nbSolar, nbTime, nbSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 66, 48) (800, 3, 48)\n"
     ]
    }
   ],
   "source": [
    "loadScaler = MinMaxScaler()\n",
    "solarScaler = MinMaxScaler()\n",
    "\n",
    "loadScaler.fit(loadMatrix.reshape(nbSample, -1))\n",
    "solarScaler.fit(solarMatrix.reshape(nbSample, -1))\n",
    "\n",
    "loadNormalized = loadScaler.transform(loadMatrix.reshape(nbSample, -1))\n",
    "solarNormalized = solarScaler.transform(solarMatrix.reshape(nbSample, -1))\n",
    "\n",
    "loadNormalized = loadNormalized.reshape(-1, nbBus, nbTime)\n",
    "solarNormalized = solarNormalized.reshape(nbSample, -1, nbTime)\n",
    "\n",
    "# plt.plot(solarNormalized[0, 1,:])\n",
    "print(loadNormalized.shape, solarNormalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{20.0: 160, 40.0: 160, 60.0: 160, 80.0: 160, 100.0: 160}\n",
      "(800, 767300) (800, 767300) (400, 3)\n"
     ]
    }
   ],
   "source": [
    "charging_station = np.squeeze(pd.read_csv(os.path.join(os.path.join(os.getcwd(), 'systemData'), 'cs_params_variable.csv')).to_numpy())\n",
    "nbCS = len(charging_station)\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'systemData')\n",
    "EV_routes = pd.read_csv(os.path.join(data_dir, 'EV_routes.csv')).to_numpy()\n",
    "nbRoute = EV_routes.shape[0]\n",
    "\n",
    "max_EV = 100\n",
    "max_pad_schedule = max_EV*4\n",
    "max_pad_bin = max_EV * (nbRoute*(nbTime-1) + nbCS*nbTime*2)\n",
    "\n",
    "# uncomment to check number of EV in dataset\n",
    "unique, counts = np.unique([x[\"Binary\"].shape[0] / (nbRoute*(nbTime-1) + nbCS*nbTime*2) for x in sample], return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "# scheduleMatrix = [x[\"Schedule\"] for x in sample]\n",
    "\n",
    "binaryMatrix = np.array([np.pad(x[\"Binary\"], ((0,max_pad_bin - x[\"Binary\"].shape[0]),), 'constant', constant_values=0) for x in sample])\n",
    "indicesMatrix = np.array([np.pad(x[\"Indices\"], ((0,max_pad_bin - x[\"Indices\"].shape[0]),), 'constant', constant_values=0) for x in sample])\n",
    "scheduleMatrix = np.array([np.pad(x[\"Schedule\"], ((0,max_pad_schedule - int(x[\"Schedule\"].shape[0])),(0,0)), 'constant', constant_values=0) for x in sample]).astype(\"int16\")\n",
    "\n",
    "print(binaryMatrix.shape, indicesMatrix.shape, scheduleMatrix[4].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 48)\n"
     ]
    }
   ],
   "source": [
    "# transform schedule to time array\n",
    "processedScheduleList = []\n",
    "\n",
    "for i in range(len(scheduleMatrix)):\n",
    "\n",
    "    scheduleArray = np.zeros((int(scheduleMatrix[i].shape[0]/4), nbTime))\n",
    "\n",
    "    for s in range(scheduleMatrix[i].shape[0]):\n",
    "        scheduleArray[scheduleMatrix[i][s,0], scheduleMatrix[i][s,2]] = scheduleMatrix[i][s,1]\n",
    "        \n",
    "    processedScheduleList.append(scheduleArray)\n",
    "\n",
    "print(processedScheduleList[6].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# since schedule size always not the same, need to do scaler separately\n",
    "destinationList = []\n",
    "\n",
    "for i in range(len(scheduleMatrix)):\n",
    "    for s in range(scheduleMatrix[i].shape[0]):\n",
    "        destinationList.append(scheduleMatrix[i][s,1])\n",
    "        destinationList.append(scheduleMatrix[i][s,2])\n",
    "\n",
    "maxDest = np.max(destinationList)\n",
    "print(maxDest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "# do a simple scaling (not MinMaxScaler)\n",
    "scheduleListNormalized = []\n",
    "\n",
    "for i in range(len(processedScheduleList)):\n",
    "    scheduleListNormalized.append(processedScheduleList[i]/maxDest)\n",
    "\n",
    "print(len(scheduleListNormalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 (169, 48)\n",
      "800 (767300,)\n",
      "800 (767300,)\n"
     ]
    }
   ],
   "source": [
    "featureList = []\n",
    "\n",
    "for i in range(len(loadNormalized)):\n",
    "\n",
    "    feature = np.append(loadNormalized[i], solarNormalized[i], axis=0)\n",
    "    feature = np.append(feature, scheduleListNormalized[i], axis=0)\n",
    "    # feature = np.transpose(feature, (1,0))\n",
    "\n",
    "    featureList.append(feature)\n",
    "\n",
    "featureList = np.array(featureList)\n",
    "\n",
    "print(len(featureList), featureList[7].shape)\n",
    "print(len(binaryMatrix), binaryMatrix[7].shape)\n",
    "print(len(indicesMatrix), indicesMatrix[7].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Rest of the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "solTimeMatrix = np.array([x[\"solve_time\"] for x in sample])\n",
    "objValMatrix = np.array([x[\"Obj_val\"] for x in sample])\n",
    "nbEVMatrix = np.array([x[\"nbEV\"] for x in sample])\n",
    "modelNumMatrix = np.array([x[\"model\"] for x in sample])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 169, 48) (80, 169, 48)\n",
      "(720, 767300) (80, 767300)\n",
      "(720, 767300) (80, 767300)\n",
      "(80,)\n",
      "(80,)\n",
      "(80, 400, 3)\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "train_idx, val_idx = train_test_split(np.arange(len(loadNormalized)), test_size=0.1, random_state=42)\n",
    "\n",
    "feature_train = featureList[train_idx]\n",
    "feature_val = featureList[val_idx]\n",
    "print(feature_train.shape, feature_val.shape)\n",
    "\n",
    "binary_train = binaryMatrix[train_idx]\n",
    "binary_val = binaryMatrix[val_idx]\n",
    "print(binary_train.shape, binary_val.shape)\n",
    "\n",
    "indices_train = indicesMatrix[train_idx]\n",
    "indices_val = indicesMatrix[val_idx]\n",
    "print(indices_train.shape, indices_val.shape)\n",
    "\n",
    "solTime_val = solTimeMatrix[val_idx]\n",
    "objVal_val = objValMatrix[val_idx]\n",
    "schedule_val = scheduleMatrix[val_idx]\n",
    "model_val = modelNumMatrix[val_idx]\n",
    "\n",
    "print(solTime_val.shape)\n",
    "print(objVal_val.shape)\n",
    "print(schedule_val.shape)\n",
    "print(model_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dir = os.path.join(os.getcwd(), f\"dataGeneration/preprocessed_data_nopadding_{interval}\")\n",
    "\n",
    "np.save(os.path.join(train_test_dir, \"X_train.npy\"), feature_train)\n",
    "np.save(os.path.join(train_test_dir, \"X_val.npy\"), feature_val)\n",
    "\n",
    "np.save(os.path.join(train_test_dir, \"y_train.npy\"), binary_train)\n",
    "np.save(os.path.join(train_test_dir, \"y_val.npy\"), binary_val)\n",
    "\n",
    "np.save(os.path.join(train_test_dir, \"indices_train.npy\"), indices_train)\n",
    "np.save(os.path.join(train_test_dir, \"indices_val.npy\"), indices_val)\n",
    "\n",
    "np.save(os.path.join(train_test_dir, \"solTime_val.npy\"), solTime_val)\n",
    "np.save(os.path.join(train_test_dir, \"objVal_val.npy\"), objVal_val)\n",
    "np.save(os.path.join(train_test_dir, \"schedule_val.npy\"), schedule_val)\n",
    "np.save(os.path.join(train_test_dir, \"model_val.npy\"), model_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
